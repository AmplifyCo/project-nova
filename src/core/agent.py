"""Core autonomous agent with self-contained execution loop."""

import asyncio
import logging
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
from pathlib import Path
import json
import yaml

from .config import AgentConfig
from .types import ToolResult, Message
from .tools.registry import ToolRegistry
from .brain.core_brain import CoreBrain
from .brain.digital_clone_brain import DigitalCloneBrain
from ..integrations.anthropic_client import AnthropicClient
from .nervous_system.state_machine import AgentStateMachine, AgentState

logger = logging.getLogger(__name__)


class AutonomousAgent:
    """Main autonomous agent with self-contained execution loop."""

    def __init__(
        self,
        config: AgentConfig,
        brain: Union[CoreBrain, DigitalCloneBrain] = None
    ):
        """Initialize the autonomous agent.

        Args:
            config: Agent configuration
            brain: Brain instance (CoreBrain or DigitalCloneBrain)
        """
        self.config = config
        self.api_client = AnthropicClient(config.api_key)

        # Load YAML config for tool registry
        yaml_config = {}
        config_path = Path("config/agent.yaml")
        if config_path.exists():
            with open(config_path, 'r') as f:
                yaml_config = yaml.safe_load(f) or {}

        # Initialize tools with safety configuration
        tool_config = yaml_config.get("agent", {})
        self.tools = ToolRegistry(config=tool_config)
        self.brain = brain

        # Nervous System: state machine for tracking execution state + cancellation
        self.state_machine = AgentStateMachine()

        logger.info(f"Initialized AutonomousAgent with {config.default_model}")

    async def run(
        self,
        task: str,
        max_iterations: Optional[int] = None,
        system_prompt: Optional[str] = None,
        pii_map: Optional[Dict[str, str]] = None
    ) -> str:
        """Execute task autonomously until completion.

        Args:
            task: Task description to execute
            max_iterations: Maximum iterations (defaults to config)
            system_prompt: Optional custom system prompt

        Returns:
            Final result as string
        """
        max_iterations = max_iterations or self.config.max_iterations

        # Store current task for semantic validation (Layer 11)
        self._current_task = task

        # Reset state machine + policy gate for new run
        self.state_machine.reset()
        self.tools.policy_gate.reset_run_counts()
        self.state_machine.transition(AgentState.THINKING, task[:80])

        logger.info(f"Starting autonomous execution: {task}")
        logger.info(f"Max iterations: {max_iterations}")

        # Load context from brain if available
        context = ""
        if self.brain:
            if hasattr(self.brain, 'get_relevant_context'):
                context = await self.brain.get_relevant_context(task)
                logger.debug(f"Loaded context from brain ({len(context)} chars)")

        # Build system prompt
        if not system_prompt:
            system_prompt = self._build_system_prompt(context)

        # Initialize conversation with task
        messages: List[Dict[str, Any]] = [
            {"role": "user", "content": task}
        ]

        # Autonomous execution loop
        iteration = 0
        final_result = None

        while iteration < max_iterations:
            iteration += 1
            logger.info(f"Iteration {iteration}/{max_iterations}")

            try:
                # Check for cancellation
                if self.state_machine.is_cancelled():
                    logger.info("Task cancelled by user")
                    self.state_machine.reset()
                    return "Task cancelled."

                # Call Claude API
                self.state_machine.transition(AgentState.THINKING)
                response = await self.api_client.create_message(
                    model=self.config.default_model,
                    messages=messages,
                    tools=self.tools.get_tool_definitions(),
                    system=system_prompt,
                    max_tokens=4096
                )

                # Process response
                if response.stop_reason == "end_turn":
                    # Task complete
                    final_result = self._extract_text_from_response(response)
                    logger.info("Task completed (end_turn)")
                    break

                elif response.stop_reason == "tool_use":
                    # Execute tools
                    self.state_machine.transition(AgentState.EXECUTING)
                    logger.info("Executing tool calls...")

                    # Add assistant message
                    messages.append({
                        "role": "assistant",
                        "content": response.content
                    })

                    # Execute all tool calls
                    tool_results = await self._execute_tool_calls(response.content, pii_map)

                    # Add tool results as user message
                    messages.append({
                        "role": "user",
                        "content": tool_results
                    })

                elif response.stop_reason == "max_tokens":
                    # Continue with more tokens
                    logger.warning("Hit max tokens, continuing...")
                    messages.append({
                        "role": "assistant",
                        "content": response.content
                    })
                    continue

                else:
                    # Unknown stop reason
                    logger.warning(f"Unknown stop reason: {response.stop_reason}")
                    final_result = self._extract_text_from_response(response)
                    break

                # Store interaction in brain
                if self.brain and hasattr(self.brain, 'memory'):
                    await self._store_interaction(task, response)

            except Exception as e:
                error_str = str(e)
                logger.error(f"Error in iteration {iteration}: {e}", exc_info=True)

                # Rate limit — wait and retry instead of crashing
                if "429" in error_str or "rate_limit" in error_str:
                    wait_time = min(60 * (2 ** (iteration - 1)), 300)  # Exponential backoff, max 5 min
                    logger.warning(f"Rate limited. Waiting {wait_time}s before retry...")
                    await asyncio.sleep(wait_time)
                    continue

                # Other errors — retry with limit
                if iteration < self.config.retry_attempts:
                    logger.info(f"Retrying... (attempt {iteration + 1})")
                    continue
                else:
                    raise

        # Handle max iterations reached
        if iteration >= max_iterations and not final_result:
            logger.warning(f"Reached max iterations ({max_iterations})")
            final_result = "Max iterations reached. Task may be incomplete."

        logger.info(f"Execution complete after {iteration} iterations")
        self.state_machine.transition(AgentState.RESPONDING)
        self.state_machine.reset()
        return final_result or "Task completed"

    async def _execute_tool_calls(
        self,
        content: List[Any],
        pii_map: Optional[Dict[str, str]] = None
    ) -> List[Dict[str, Any]]:
        """Execute tool calls from Claude's response (parallel when safe).

        Args:
            content: Response content blocks

        Returns:
            List of tool result content blocks
        """
        # Collect all tool_use blocks
        tool_blocks = [b for b in content if b.type == "tool_use"]

        if not tool_blocks:
            return []

        # Execute all tool calls in parallel
        async def _run_single_tool(block):
            tool_name = block.name
            tool_input = block.input
            tool_use_id = block.id

            # De-tokenize PII in tool inputs if map provided
            if pii_map:
                # Recursive de-tokenization for nested dicts/lists
                def detokenize_value(val):
                    if isinstance(val, str):
                        for placeholder, original in pii_map.items():
                            val = val.replace(placeholder, original)
                        return val
                    elif isinstance(val, dict):
                        return {k: detokenize_value(v) for k, v in val.items()}
                    elif isinstance(val, list):
                        return [detokenize_value(v) for v in val]
                    return val

                try:
                    tool_input = detokenize_value(tool_input)
                    logger.debug(f"De-tokenized tool input for {tool_name}")
                except Exception as e:
                    logger.warning(f"Failed to de-tokenize tool input: {e}")

            logger.info(f"Executing tool: {tool_name}")
            logger.debug(f"Tool input: {tool_input}")

            result = await self.tools.execute_tool(
                tool_name,
                user_message=getattr(self, '_current_task', ''),
                llm_client=self.api_client,
                **tool_input
            )

            # Build content: multimodal (screenshot+text) or plain string
            if result.success and result.content_blocks is not None:
                content = result.content_blocks
            elif result.success:
                content = result.output or ""
            else:
                content = f"Error: {result.error}"

            tool_result = {
                "type": "tool_result",
                "tool_use_id": tool_use_id,
                "content": content,
            }

            if not result.success:
                tool_result["is_error"] = True

            logger.info(f"Tool {tool_name}: {'Success' if result.success else 'Failed'}")
            return tool_result

        # Single tool: run directly. Multiple tools: run in parallel.
        if len(tool_blocks) == 1:
            return [await _run_single_tool(tool_blocks[0])]

        logger.info(f"Running {len(tool_blocks)} tool calls in parallel")
        results = await asyncio.gather(
            *[_run_single_tool(b) for b in tool_blocks],
            return_exceptions=True
        )

        # Handle any exceptions from gather
        tool_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Tool {tool_blocks[i].name} raised exception: {result}")
                tool_results.append({
                    "type": "tool_result",
                    "tool_use_id": tool_blocks[i].id,
                    "content": f"Error: {str(result)}",
                    "is_error": True
                })
            else:
                tool_results.append(result)

        return tool_results

    def _extract_text_from_response(self, response) -> str:
        """Extract text content from Claude response.

        Args:
            response: API response

        Returns:
            Extracted text
        """
        text_parts = []

        for block in response.content:
            if hasattr(block, 'text'):
                text_parts.append(block.text)

        return "\n".join(text_parts) if text_parts else ""

    def _build_system_prompt(self, context: str = "") -> str:
        """Build system prompt for the agent.

        Args:
            context: Optional context from brain

        Returns:
            System prompt string
        """
        prompt = """You are an autonomous AI agent with the ability to execute tasks independently.

You have access to tools for:
- Executing bash commands
- Reading and writing files
- Fetching web content

Your goal is to complete the given task autonomously. Work methodically:
1. Analyze the task
2. Break it into steps
3. Use available tools to accomplish each step
4. Verify your work
5. Report completion

Be thorough, check for errors, and only report completion when the task is truly done.

COMMUNICATION STYLE:
- Be EXTREMELY concise — 1-2 sentences for confirmations, short paragraphs only when needed
- Never add filler, preambles, or unsolicited tips ("Here's what I did...", "You can now...")
- Use natural, conversational language
- Just confirm the action or answer the question, nothing more

CRITICAL REQUIREMENTS:
- NEVER hallucinate or provide synthetic/made-up information
- Only provide factual information based on actual data from tools
- If you don't know something, say so clearly rather than guessing
- Base all responses on verified information from tool outputs
- NEVER wrap your response in XML tags (no <result>, <attemptcompletion>, <analysis>, etc.)
- Respond in plain text or Markdown only"""

        if context:
            prompt += f"\n\nRelevant context:\n{context}"

        return prompt

    async def _store_interaction(self, task: str, response):
        """Store interaction in brain for future reference.

        Args:
            task: Original task
            response: API response
        """
        try:
            # Extract key information
            text = self._extract_text_from_response(response)

            # Store in brain's memory
            await self.brain.memory.store(
                text=f"Task: {task}\nResponse: {text}",
                metadata={
                    "type": "interaction",
                    "task": task,
                    "timestamp": datetime.now().isoformat(),
                    "stop_reason": response.stop_reason
                }
            )

            logger.debug("Stored interaction in brain")

        except Exception as e:
            logger.warning(f"Failed to store interaction in brain: {e}")

    @classmethod
    def from_config(cls, config_path: str = ".env"):
        """Create agent from configuration file.

        Args:
            config_path: Path to .env file

        Returns:
            AutonomousAgent instance
        """
        from .config import load_config

        config = load_config(config_path)

        # Initialize appropriate brain
        if config.self_build_mode:
            brain = CoreBrain(config.core_brain_path)
        else:
            brain = DigitalCloneBrain(config.digital_clone_brain_path)

        return cls(config, brain)
